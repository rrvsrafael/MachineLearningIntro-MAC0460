{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>against_electric</th>\n",
       "      <th>attack</th>\n",
       "      <th>base_egg_steps</th>\n",
       "      <th>base_happiness</th>\n",
       "      <th>base_total</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>defense</th>\n",
       "      <th>experience_growth</th>\n",
       "      <th>height_m</th>\n",
       "      <th>hp</th>\n",
       "      <th>percentage_male</th>\n",
       "      <th>sp_attack</th>\n",
       "      <th>sp_defense</th>\n",
       "      <th>speed</th>\n",
       "      <th>type1</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48</td>\n",
       "      <td>5120</td>\n",
       "      <td>70</td>\n",
       "      <td>314</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>1059860</td>\n",
       "      <td>0.5</td>\n",
       "      <td>44</td>\n",
       "      <td>88.1</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "      <td>water</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>63</td>\n",
       "      <td>5120</td>\n",
       "      <td>70</td>\n",
       "      <td>405</td>\n",
       "      <td>45</td>\n",
       "      <td>80</td>\n",
       "      <td>1059860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>88.1</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>water</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>103</td>\n",
       "      <td>5120</td>\n",
       "      <td>70</td>\n",
       "      <td>630</td>\n",
       "      <td>45</td>\n",
       "      <td>120</td>\n",
       "      <td>1059860</td>\n",
       "      <td>1.6</td>\n",
       "      <td>79</td>\n",
       "      <td>88.1</td>\n",
       "      <td>135</td>\n",
       "      <td>115</td>\n",
       "      <td>78</td>\n",
       "      <td>water</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>3840</td>\n",
       "      <td>70</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>40</td>\n",
       "      <td>1059860</td>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3840</td>\n",
       "      <td>70</td>\n",
       "      <td>349</td>\n",
       "      <td>120</td>\n",
       "      <td>55</td>\n",
       "      <td>1059860</td>\n",
       "      <td>1.1</td>\n",
       "      <td>63</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "      <td>normal</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    against_electric  attack  base_egg_steps  base_happiness  base_total  \\\n",
       "6                2.0      48            5120              70         314   \n",
       "7                2.0      63            5120              70         405   \n",
       "8                2.0     103            5120              70         630   \n",
       "15               2.0      45            3840              70         251   \n",
       "16               2.0      60            3840              70         349   \n",
       "\n",
       "   capture_rate  defense  experience_growth  height_m  hp  percentage_male  \\\n",
       "6            45       65            1059860       0.5  44             88.1   \n",
       "7            45       80            1059860       1.0  59             88.1   \n",
       "8            45      120            1059860       1.6  79             88.1   \n",
       "15          255       40            1059860       0.3  40             50.0   \n",
       "16          120       55            1059860       1.1  63             50.0   \n",
       "\n",
       "    sp_attack  sp_defense  speed   type1  weight_kg  \n",
       "6          50          64     43   water        9.0  \n",
       "7          65          80     58   water       22.5  \n",
       "8         135         115     78   water       85.5  \n",
       "15         35          35     56  normal        1.8  \n",
       "16         50          50     71  normal       30.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns to be used\n",
    "columns = [\"type1\", \"against_electric\", \"attack\", \"defense\", \"sp_attack\", \"sp_defense\", \"speed\", \"hp\", \"weight_kg\",\n",
    "           \"height_m\", \"base_total\", \"base_egg_steps\", \"base_happiness\", \"capture_rate\", \"experience_growth\", \"percentage_male\"]\n",
    "\n",
    "# Read data from csv\n",
    "df = pd.read_csv(\"pokemon.csv\", usecols=columns)\n",
    "\n",
    "# Drop rows with missing values, and unnecessary classes\n",
    "df = df.dropna()\n",
    "df = df[df.type1.isin(['water', 'normal'])]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform wanted classes into a binary variable\n",
    "df[\"type1\"] = df[\"type1\"].replace(\"water\", 1)\n",
    "df[\"type1\"] = df[\"type1\"].replace(\"normal\", 0)\n",
    "\n",
    "# Convert to numeric values\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "# Normalize data\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# Remove outliers: rows with a z-score greater than 3\n",
    "df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "\n",
    "# Transform wanted classes back to their original values\n",
    "df[\"type1\"] = df[\"type1\"].replace(1, \"water\")\n",
    "df[\"type1\"] = df[\"type1\"].replace(0, \"normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vertically-oriented swarms of points for each feature\n",
    "df_melt = pd.melt(df, \"type1\", var_name=\"Feature\")\n",
    "\n",
    "# Plot individual distributions for desired features\n",
    "for feature in columns[1:]:\n",
    "    plt.figure(figsize=(4, 3), dpi=300)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    sns.swarmplot(x=\"Feature\", y=\"value\", hue=\"type1\",\n",
    "                    edgecolor=\"grey\", alpha=.7, linewidth=.5, data=df_melt[df_melt[\"Feature\"] == feature])\n",
    "    plt.savefig(\"swarmplot_\" + feature + \".png\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the presence of multiple points sharing the same value, a significant portion of them overlap in the visualization. While Swarmplot addresses this issue by spreading out the points, an alternative option is Stripplot. However, it should be noted that Stripplot, despite handling overlapping points, may present a more challenging visualization.\n",
    "\n",
    "# sns.stripplot(x=\"Feature\", y=\"value\", hue=\"type1\", alpha=0.5, data=df_melt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = df.drop(\"type1\", axis=1)\n",
    "y = df[\"type1\"]\n",
    "\n",
    "# Split data into train, test and validation sets\n",
    "X_, X_validation, y_, y_validation = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_, y_, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers to be used\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(),\n",
    "    GaussianNB(),\n",
    "    SGDClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "# Define classifiers names\n",
    "names = [\n",
    "    \"Logistic Regression\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"SVC (SVM)\",\n",
    "    \"Nearest Neighbors\",\n",
    "    \"MLPClassifier (Neural Net)\",\n",
    "    \"GaussianNB (Naive Bayes)\",\n",
    "    \"SGDClassifier\",\n",
    "    \"Linear Discriminant Analysis\",\n",
    "    \"Quadratic Discriminant Analysis\",\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters to be tested for each classifier\n",
    "\n",
    "- LogisticRegression: C is the inverse of regularization strength. Solver is the solver for weight optimization. Max_iter is the maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "- DecisionTree: Criterion is the function to measure the quality of a split. Max_depth is the maximum depth of the tree. Min_samples_leaf is the minimum number of samples required to be at a leaf node.\n",
    "\n",
    "- RandomForest: N_estimators is the number of trees in the forest. Max_depth is the maximum depth of the tree. Min_samples_leaf is the minimum number of samples required to be at a leaf node.\n",
    "\n",
    "- SVC: Kernel is the kernel type to be used in the algorithm. C is the penalty parameter of the error term. Degree is the degree of the polynomial kernel function.\n",
    "\n",
    "- KNeighborsClassifier: N_neighbors is the number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "- MLPClassifier: Hidden_layer_sizes is the number of neurons in the ith hidden layer. Activation is the activation function for the hidden layer. Alpha is the L2 penalty (regularization term) parameter.\n",
    "\n",
    "- GaussianNB: Var_smoothing is the portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "    \n",
    "- SGDClassifier: Loss is the loss function to be used. Alpha is the constant that multiplies the regularization term.\n",
    "\n",
    "- LinearDiscriminantAnalysis: Solver is the solver to use, possible values: svd, lsqr, eigen. Shrinkage is the shrinkage parameter, possible values: auto, float between 0 and 1.\n",
    "\n",
    "- QuadraticDiscriminantAnalysis: Reg_param is the regularization parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_params = [\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10], 'solver': [\n",
    "        'liblinear', 'saga'], 'max_iter': [1000]},\n",
    "]\n",
    "decisiontree_params = [\n",
    "    {'criterion': ['gini', 'entropy'], 'max_depth': [\n",
    "        2, 4, 6, 8, 10,], 'min_samples_leaf': [1, 2, 3, 4, 5,]},\n",
    "]\n",
    "randomforest_params = [\n",
    "    {'n_estimators': [10, 100, 1000], 'max_depth': [\n",
    "        2, 4, 6, 8, 10,], 'min_samples_leaf': [1, 2, 3, 4, 5,], }\n",
    "]\n",
    "svm_params = [\n",
    "    {'kernel': ['linear', 'poly', 'rbf'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10], 'degree': [2, 3, 4, 5, 6,]},\n",
    "]\n",
    "knn_params = [\n",
    "    {'n_neighbors': [1, 2, 3, 4, 5,], 'weights': ['uniform', 'distance']},\n",
    "]\n",
    "mlp_params = [\n",
    "    {'hidden_layer_sizes': [(10,), (50,), (100,)], 'activation': [\n",
    "        'identity', 'logistic', 'tanh'], 'solver': ['lbfgs', 'sgd', 'adam']},\n",
    "]\n",
    "naivebayes_params = [\n",
    "    {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]},\n",
    "]\n",
    "sgd_params = [\n",
    "    {'loss': ['log', 'squared_hinge', 'perceptron'], 'alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
    "]\n",
    "lda_params = [\n",
    "    {'solver': ['svd', 'lsqr', 'eigen']},\n",
    "]\n",
    "qda_params = [\n",
    "    {'reg_param': [0, 0.001, 0.01, 0.1, 1]},\n",
    "]\n",
    "\n",
    "# Aggregate all parameters in a list\n",
    "params = [\n",
    "    logreg_params,\n",
    "    decisiontree_params,\n",
    "    randomforest_params,\n",
    "    svm_params,\n",
    "    knn_params,\n",
    "    mlp_params,\n",
    "    naivebayes_params,\n",
    "    sgd_params,\n",
    "    lda_params,\n",
    "    qda_params,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Best parameters set found:  {'C': 10, 'max_iter': 1000, 'solver': 'saga'}\n",
      "Grid scores: Mean = 0.665, Standard deviation = 0.061\n",
      "Test set result: Accuracy = 0.750\n",
      "Validation set result: Accuracy = 0.743\n",
      "\n",
      "Decision Tree\n",
      "Best parameters set found:  {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 1}\n",
      "Grid scores: Mean = 0.773, Standard deviation = 0.061\n",
      "Test set result: Accuracy = 0.893\n",
      "Validation set result: Accuracy = 0.829\n",
      "\n",
      "Random Forest\n",
      "Best parameters set found:  {'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 1000}\n",
      "Grid scores: Mean = 0.797, Standard deviation = 0.072\n",
      "Test set result: Accuracy = 0.786\n",
      "Validation set result: Accuracy = 0.771\n",
      "\n",
      "SVC (SVM)\n",
      "Best parameters set found:  {'C': 10, 'degree': 3, 'kernel': 'poly'}\n",
      "Grid scores: Mean = 0.637, Standard deviation = 0.039\n",
      "Test set result: Accuracy = 0.643\n",
      "Validation set result: Accuracy = 0.714\n",
      "\n",
      "Nearest Neighbors\n",
      "Best parameters set found:  {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "Grid scores: Mean = 0.727, Standard deviation = 0.108\n",
      "Test set result: Accuracy = 0.857\n",
      "Validation set result: Accuracy = 0.743\n",
      "\n",
      "MLPClassifier (Neural Net)\n",
      "Best parameters set found:  {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'solver': 'lbfgs'}\n",
      "Grid scores: Mean = 0.662, Standard deviation = 0.070\n",
      "Test set result: Accuracy = 0.714\n",
      "Validation set result: Accuracy = 0.914\n",
      "\n",
      "GaussianNB (Naive Bayes)\n",
      "Best parameters set found:  {'var_smoothing': 1e-08}\n",
      "Grid scores: Mean = 0.608, Standard deviation = 0.109\n",
      "Test set result: Accuracy = 0.679\n",
      "Validation set result: Accuracy = 0.743\n",
      "\n",
      "SGDClassifier\n",
      "Best parameters set found:  {'alpha': 0.01, 'loss': 'log'}\n",
      "Grid scores: Mean = 0.631, Standard deviation = 0.064\n",
      "Test set result: Accuracy = 0.750\n",
      "Validation set result: Accuracy = 0.686\n",
      "\n",
      "Linear Discriminant Analysis\n",
      "Best parameters set found:  {'solver': 'svd'}\n",
      "Grid scores: Mean = nan, Standard deviation = nan\n",
      "Test set result: Accuracy = 0.679\n",
      "Validation set result: Accuracy = 0.771\n",
      "\n",
      "Quadratic Discriminant Analysis\n",
      "Best parameters set found:  {'reg_param': 0.01}\n",
      "Grid scores: Mean = 0.693, Standard deviation = 0.063\n",
      "Test set result: Accuracy = 0.714\n",
      "Validation set result: Accuracy = 0.743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over classifiers, training and testing them, using GridSearchCV to find the best parameters for each one\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    clf = GridSearchCV(clf, params[names.index(name)], cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found: \", clf.best_params_)\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    print(\"Grid scores: Mean = %0.3f, Standard deviation = %0.3f\" % \n",
    "          (means.mean(), stds.mean()))\n",
    "\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(\"Test set result: Accuracy = %0.3f\" % accuracy_score(y_true, y_pred))\n",
    "\n",
    "    y_true, y_pred = y_validation, clf.predict(X_validation)\n",
    "    print(\"Validation set result: Accuracy = %0.3f\" %\n",
    "          accuracy_score(y_true, y_pred))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.title(\"Confusion Matrix for \" + name)\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", \n",
    "                fmt=\"d\", cbar=False, annot_kws={\"size\": 20}, \n",
    "                xticklabels=[\"Actual: normal\", \"Actual: water\"],\n",
    "                yticklabels=[\"Predicted: normal\", \"Predicted: water\"])\n",
    "    plt.savefig(\"confusion_matrix_\" + name + \".png\")\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
